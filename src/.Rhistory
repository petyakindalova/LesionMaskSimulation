#install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("oro.nifti")
#install.packages("pryr")
#install.packages("enrichwith")
#install.packages("lpSolveAPI")
#install.packages("brglm2")
#install.packages("detectseparation")
#install.packages("devtools")
#devtools::install_github("ikosmidis/waldi", force=T)
#install.packages("foreach")
#install.packages("doParallel")
#install.packages("iterators")
library(oro.nifti)
library(pryr)
library(enrichwith)
library(lpSolveAPI)
library(brglm2)
library(detectseparation)
library(devtools)
library(waldi)
library(foreach)
library(doParallel)
library(iterators)
PATH_PROJ = "D:/Neuroimaging/Simulations/LesionMaskSimulation/" # Project path
#
PATH_DATA = file.path(PATH_PROJ, 'data', 'simulated_data') # Path where simulated lesion masks are stored
training_dataset = read.table(paste0(PATH_DATA, "/GLM_sample1000.dat"), header=T)
#
PATH_TEMP = file.path(PATH_PROJ, 'data', 'temp') # Path where temporary files will be stored
PATH_RESULTS = file.path(PATH_PROJ, 'results', 'MeanBR') # Path where GLM results are saved
#PATH_RESULTS = file.path(PATH_PROJ, 'results', 'ML') # change to ML if you are planning to obtain MLEs
#
PATH_SRC = file.path(PATH_PROJ, 'src') # Path where some help functions are stored
source(paste0(PATH_SRC, "/empir_prob_step1.R"))
source(paste0(PATH_SRC, "/lesion_matrix_step2.R"))
source(paste0(PATH_SRC, "/glm_step3.R"))
source(paste0(PATH_SRC, "/map_to_masks_step4.R"))
n_covs_cat = 0 # number of categorical covariates
n_covs_cont = 1 # number of continuous covariates
n_covs = n_covs_cat + n_covs_cont
empir_avail = 1 # flag: 0 (empirical probability is not available), 1 (empirical probability is available)
n_cores = 2 # number of cores for parallel GLM
link_fn = "probit" # options are logit and probit
method = 2 # 1: ML, 2: MeanBR
method_name = "MeanBR" # "ML" or "MeanBR"
brain_mask = readNIfTI(paste0(PATH_PROJ, "/data/MNI152_T1_2mm_brain_mask.nii")) #MNI 2mm brain mask
mapping = read.table(paste0(PATH_TEMP, "/voxel_IDs.dat"), header=F)
mapping = as.matrix(mapping, nrow = 1)
n_subsets = ceiling(length(mapping)/1000)
print("number of subsets of voxels")
print(n_subsets)
filename_subset = paste0(PATH_TEMP, "/GLM_subset_",1, "_", method_name, "_Nvars_", n_covs,"_results.RData")
load(filename_subset)
n_coefs = length(output[[1]]$parameter) #obtain number of coefficients since it may differ from n_covs
Sys.time()
mapping_fn_vol2(brain_mask = brain_mask,
tempdir = PATH_TEMP,
mapping = mapping,
n_subsets = n_subsets,
n_covs = n_covs,
n_coefs = n_coefs,
GLMmethod = method,
outputdir = PATH_RESULTS)
Sys.time()
mapping = read.table(paste0(PATH_TEMP, "/voxel_IDs.dat"), header=F)
mapping = as.matrix(mapping, nrow = 1)
n_subsets = ceiling(length(mapping)/1000)
print("number of subsets of voxels")
print(n_subsets)
filename_subset = paste0(PATH_TEMP, "/GLM_subset_",1, "_", method_name, "_Nvars_", n_covs,"_results.RData")
load(filename_subset)
n_coefs = length(output[[1]]$parameter) #obtain number of coefficients since it may differ from n_covs
Sys.time()
mapping_fn_vol2(brain_mask = brain_mask,
tempdir = PATH_TEMP,
mapping = mapping,
n_subsets = n_subsets,
n_covs = n_covs,
n_coefs = n_coefs,
GLMmethod = method,
outputdir = PATH_RESULTS)
source(paste0(PATH_SRC, "/map_to_masks_step4.R"))
mapping = read.table(paste0(PATH_TEMP, "/voxel_IDs.dat"), header=F)
mapping = as.matrix(mapping, nrow = 1)
n_subsets = ceiling(length(mapping)/1000)
print("number of subsets of voxels")
print(n_subsets)
filename_subset = paste0(PATH_TEMP, "/GLM_subset_",1, "_", method_name, "_Nvars_", n_covs,"_results.RData")
load(filename_subset)
n_coefs = length(output[[1]]$parameter) #obtain number of coefficients since it may differ from n_covs
Sys.time()
mapping_fn_vol2(brain_mask = brain_mask,
tempdir = PATH_TEMP,
mapping = mapping,
n_subsets = n_subsets,
n_covs = n_covs,
n_coefs = n_coefs,
GLMmethod = method,
outputdir = PATH_RESULTS)
Sys.time()
mapping = read.table(paste0(PATH_TEMP, "/voxel_IDs.dat"), header=F)
mapping = as.matrix(mapping, nrow = 1)
n_subsets = ceiling(length(mapping)/1000)
print("number of subsets of voxels")
print(n_subsets)
filename_subset = paste0(PATH_TEMP, "/GLM_subset_",1, "_", method_name, "_Nvars_", n_covs,"_results.RData")
load(filename_subset)
n_coefs = length(output[[1]]$parameter) #obtain number of coefficients since it may differ from n_covs
Sys.time()
mapping_fn_vol2(brain_mask = brain_mask,
tempdir = PATH_TEMP,
mapping = mapping,
n_subsets = n_subsets,
n_covs = n_covs,
n_coefs = n_coefs,
GLMmethod = method,
outputdir = PATH_RESULTS)
Sys.time()
source(paste0(PATH_SRC, "/map_to_masks_step4.R"))
mapping = read.table(paste0(PATH_TEMP, "/voxel_IDs.dat"), header=F)
mapping = as.matrix(mapping, nrow = 1)
n_subsets = ceiling(length(mapping)/1000)
print("number of subsets of voxels")
print(n_subsets)
filename_subset = paste0(PATH_TEMP, "/GLM_subset_",1, "_", method_name, "_Nvars_", n_covs,"_results.RData")
load(filename_subset)
n_coefs = length(output[[1]]$parameter) #obtain number of coefficients since it may differ from n_covs
Sys.time()
mapping_fn_vol2(brain_mask = brain_mask,
tempdir = PATH_TEMP,
mapping = mapping,
n_subsets = n_subsets,
n_covs = n_covs,
n_coefs = n_coefs,
GLMmethod = method,
outputdir = PATH_RESULTS)
Sys.time()
coefs_br = readNIfTI("D:/Neuroimaging/Simulations/LesionMaskSimulation/results/MeanBR/coef_age_nvars_1_method_2.nii.gz")
summary(coefs_br[empir_prob_mask!=0&brain_mask==1])
summary(coefs_br)
summary(coefs_br[brain_mask==1])
library(oro.nifti)
library(neurobase)
library(pryr)
library(enrichwith)
library(lpSolveAPI)
library(brglm2)
library(detectseparation)
library(devtools)
library(waldi)
library(foreach)
library(doParallel)
library(iterators)
PATH_PROJ = "D:/Neuroimaging/Simulations/LesionMaskSimulation/" # Project path
#
PATH_DATA = file.path(PATH_PROJ, 'data', 'simulated_data') # Path where simulated lesion masks are stored
training_dataset = read.table(paste0(PATH_DATA, "/GLM_sample1000.dat"), header=T)
#
PATH_TEMP = file.path(PATH_PROJ, 'data', 'temp') # Path where temporary files will be stored
PATH_RESULTS = file.path(PATH_PROJ, 'results', 'MeanBR') # Path where GLM results are saved
#PATH_RESULTS = file.path(PATH_PROJ, 'results', 'ML') # change to ML if you are planning to obtain MLEs
#
PATH_SRC = file.path(PATH_PROJ, 'src') # Path where some help functions are stored
source(paste0(PATH_SRC, "/empir_prob_step1.R"))
source(paste0(PATH_SRC, "/lesion_matrix_step2.R"))
source(paste0(PATH_SRC, "/glm_step3.R"))
source(paste0(PATH_SRC, "/map_to_masks_step4.R"))
n_covs_cat = 0 # number of categorical covariates
n_covs_cont = 1 # number of continuous covariates
n_covs = n_covs_cat + n_covs_cont
empir_avail = 1 # flag: 0 (empirical probability is not available), 1 (empirical probability is available)
n_cores = 2 # number of cores for parallel GLM
link_fn = "probit" # options are logit and probit
method = 2 # 1: ML, 2: MeanBR
method_name = "MeanBR" # "ML" or "MeanBR"
brain_mask = readNIfTI(paste0(PATH_PROJ, "/data/MNI152_T1_2mm_brain_mask.nii")) #MNI 2mm brain mask
mapping = read.table(paste0(PATH_TEMP, "/voxel_IDs.dat"), header=F)
mapping = as.matrix(mapping, nrow = 1)
n_subsets = ceiling(length(mapping)/1000)
print("number of subsets of voxels")
print(n_subsets)
filename_subset = paste0(PATH_TEMP, "/GLM_subset_",1, "_", method_name, "_Nvars_", n_covs,"_results.RData")
load(filename_subset)
n_coefs = length(output[[1]]$parameter) #obtain number of coefficients since it may differ from n_covs
Sys.time()
mapping_fn_vol2(brain_mask = brain_mask,
tempdir = PATH_TEMP,
mapping = mapping,
n_subsets = n_subsets,
n_covs = n_covs,
n_coefs = n_coefs,
GLMmethod = method,
outputdir = PATH_RESULTS)
Sys.time()
#install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("oro.nifti")
#install.packages("pryr")
#install.packages("enrichwith")
#install.packages("lpSolveAPI")
#install.packages("brglm2")
#install.packages("detectseparation")
#install.packages("devtools")
#devtools::install_github("ikosmidis/waldi", force=T)
#install.packages("foreach")
#install.packages("doParallel")
#install.packages("iterators")
library(oro.nifti)
library(neurobase)
library(pryr)
library(enrichwith)
library(lpSolveAPI)
library(brglm2)
library(detectseparation)
library(devtools)
library(waldi)
library(foreach)
library(doParallel)
library(iterators)
PATH_PROJ = "D:/Neuroimaging/Simulations/LesionMaskSimulation/" # Project path
#
PATH_DATA = file.path(PATH_PROJ, 'data', 'simulated_data') # Path where simulated lesion masks are stored
training_dataset = read.table(paste0(PATH_DATA, "/GLM_sample1000.dat"), header=T)
#
PATH_TEMP = file.path(PATH_PROJ, 'data', 'temp') # Path where temporary files will be stored
PATH_RESULTS = file.path(PATH_PROJ, 'results', 'MeanBR') # Path where GLM results are saved
#PATH_RESULTS = file.path(PATH_PROJ, 'results', 'ML') # change to ML if you are planning to obtain MLEs
#
PATH_SRC = file.path(PATH_PROJ, 'src') # Path where some help functions are stored
source(paste0(PATH_SRC, "/empir_prob_step1.R"))
source(paste0(PATH_SRC, "/lesion_matrix_step2.R"))
source(paste0(PATH_SRC, "/glm_step3.R"))
source(paste0(PATH_SRC, "/map_to_masks_step4.R"))
n_covs_cat = 0 # number of categorical covariates
n_covs_cont = 1 # number of continuous covariates
n_covs = n_covs_cat + n_covs_cont
empir_avail = 1 # flag: 0 (empirical probability is not available), 1 (empirical probability is available)
n_cores = 2 # number of cores for parallel GLM
link_fn = "probit" # options are logit and probit
method = 2 # 1: ML, 2: MeanBR
method_name = "MeanBR" # "ML" or "MeanBR"
brain_mask = readNIfTI(paste0(PATH_PROJ, "/data/MNI152_T1_2mm_brain_mask.nii")) #MNI 2mm brain mask
mapping = read.table(paste0(PATH_TEMP, "/voxel_IDs.dat"), header=F)
mapping = as.matrix(mapping, nrow = 1)
n_subsets = ceiling(length(mapping)/1000)
print("number of subsets of voxels")
print(n_subsets)
filename_subset = paste0(PATH_TEMP, "/GLM_subset_",1, "_", method_name, "_Nvars_", n_covs,"_results.RData")
load(filename_subset)
n_coefs = length(output[[1]]$parameter) #obtain number of coefficients since it may differ from n_covs
Sys.time()
mapping_fn_vol2(brain_mask = brain_mask,
tempdir = PATH_TEMP,
mapping = mapping,
n_subsets = n_subsets,
n_covs = n_covs,
n_coefs = n_coefs,
GLMmethod = method,
outputdir = PATH_RESULTS)
Sys.time()
